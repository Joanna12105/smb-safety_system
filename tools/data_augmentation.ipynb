{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Enlargement of a data set for object detection\n",
        "\n",
        "This notebook can be used to enlarge a data set for object detection consisting of .jpg images and .xml files. The [Albumentations](https://albumentations.ai/docs/) library, which is a library for image augmentation, is used to modify the images.\n",
        "The following sources were used to create the notebook:\n",
        "\n",
        "\n",
        "*   https://chatgpt.com/\n",
        "*   https://www.kaggle.com/code/ankursingh12/data-augmentation-for-object-detection/notebook\n",
        "*   https://albumentations.ai/docs/\n",
        "\n",
        "\n",
        "Upload your data set in a zipped folder called \"images.zip\". It should contain the images (.jpg) and the .xml files containing the annotations for the images. The annotations should be done in the Pascal VOC format.\n",
        "\n"
      ],
      "metadata": {
        "id": "iHf4BFztRm5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip images.zip"
      ],
      "metadata": {
        "id": "MPQujyzn7LjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "images_zip = '/content/images.zip'\n",
        "os.remove(images_zip)\n",
        "print(f\"Folder '{images_zip}' and its contents have been deleted.\")"
      ],
      "metadata": {
        "id": "qDRSvcyonL-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/Joanna12105/smb-safety_system/main/tools/xml_to_csv.py\n",
        "!wget https://raw.githubusercontent.com/Joanna12105/smb-safety_system/main/tools/csv_to_xml.py"
      ],
      "metadata": {
        "id": "GISTGPMGRo9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/xml_to_csv.py"
      ],
      "metadata": {
        "id": "ym4fP0PY3syR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================================================================================\n",
        "# ================================================= IMPORTS =================================================\n",
        "# ===========================================================================================================\n",
        "import cv2\n",
        "import ast\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import albumentations as A\n",
        "\n",
        "train_folder = '/content/images/'\n",
        "\n",
        "\n",
        "# ===========================================================================================================\n",
        "# ================================================ FUNCTIONS ================================================\n",
        "# ===========================================================================================================\n",
        "\n",
        "\n",
        "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "# Function name:        load_data\n",
        "# Function Parameter:   None\n",
        "# Description:          Function to load data from the previously\n",
        "#                        created .csv and to extract the bounding box\n",
        "#                        information\n",
        "# Return:               train_df > csv data loaded into a data frame\n",
        "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "def load_data():\n",
        "    train_df = pd.read_csv('/content/org_imgs_bb.csv')\n",
        "    bboxes = np.stack(train_df['Bounding Box'].apply(lambda x: ast.literal_eval(x)))\n",
        "    for i, col in enumerate(['x_min', 'y_min', 'x_max', 'y_max']):\n",
        "        train_df[col] = bboxes[:, i]\n",
        "    return train_df\n",
        "\n",
        "\n",
        "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "# Function name:        read_img\n",
        "# Function Parameter:   img_id > unique image name, taken from the row\n",
        "#                        \"Filename\" in the data frame\n",
        "# Description:          Function to read an image from the specified\n",
        "#                        folder (train_folder) based on the provided\n",
        "#                        \"img_id\"\n",
        "# Return:               img > image data\n",
        "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "def read_img(img_id):\n",
        "    img_path = f\"{train_folder}/{img_id}.jpg\"\n",
        "    print(f\"Image read: {img_path}\")\n",
        "    img = cv2.imread(str(img_path))\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    return img\n",
        "\n",
        "\n",
        "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "# Function name:        read_bboxes\n",
        "# Function Parameter:   img_id > unique image name, taken from the row\n",
        "#                        \"Filename\" in the data frame\n",
        "#                       df > data frame\n",
        "#                       img_shape > height and width of the image\n",
        "# Description:          Function to get the bounding box information\n",
        "#                        and to normalize the bounding box data\n",
        "#                        for a certain image, defined by the image id\n",
        "# Return:               bboxes > normalized bounding box data\n",
        "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "def read_bboxes(img_id, df, img_shape):\n",
        "    bboxes = df.loc[df.Filename == img_id, ['x_min', 'y_min', 'x_max', 'y_max']].values.astype(float)\n",
        "    height, width = img_shape[:2]\n",
        "    bboxes[:, 0] /= width\n",
        "    bboxes[:, 1] /= height\n",
        "    bboxes[:, 2] /= width\n",
        "    bboxes[:, 3] /= height\n",
        "    return bboxes\n",
        "\n",
        "\n",
        "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "# Function name:        save_image\n",
        "# Function Parameter:   image > contains the image information\n",
        "#                       save_path > path under which the images are\n",
        "#                        stored at\n",
        "# Description:          Function to save an image to the specified\n",
        "#                        path\n",
        "# Return:               None\n",
        "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "def save_image(image, save_path):\n",
        "    img_bgr = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "    cv2.imwrite(save_path, img_bgr)\n",
        "    print(f\"Image saved: {save_path}\")\n",
        "\n",
        "\n",
        "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "# Function name:        organize_image_saving_and_annotation_data\n",
        "# Function Parameter:   image > contains the image information\n",
        "#                       save_path > path under which the images are\n",
        "#                        stored at\n",
        "#                       img_id > unique image name, taken from the row\n",
        "#                        \"Filename\" in the data frame\n",
        "#                       augmentation_name > stores the name of the\n",
        "#                        applied augmentation\n",
        "#                       bboxes > normalized bounding box data\n",
        "#                       original_df > the data frame that was the\n",
        "#                        \"latest\" state before the current image\n",
        "#                        was processed\n",
        "#                       bbox_indices > stores the list of indices in\n",
        "#                        the original_df DataFrame corresponding to\n",
        "#                        the bounding boxes of the current image\n",
        "# Description:          Function to organize the saving of the newly\n",
        "#                        created images and to update the dataframe\n",
        "#                        with the new bounding box annotations\n",
        "# Return:               original_df > the originally loaded data frame\n",
        "#                        gets modified by concatenating it with the\n",
        "#                        newly created data frame (new_df), which\n",
        "#                        contains the new annotations (for each image\n",
        "#                        the information gets appended)\n",
        "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "def organize_image_saving_and_annotation_data(image, img_id, augmentation_name, bboxes, original_df, bbox_indices):\n",
        "    height, width = image.shape[:2]\n",
        "    new_rows = []\n",
        "    for i, bbox in enumerate(bboxes):\n",
        "        x_min = int(bbox[0] * width)\n",
        "        y_min = int(bbox[1] * height)\n",
        "        x_max = int(bbox[2] * width)\n",
        "        y_max = int(bbox[3] * height)\n",
        "\n",
        "        save_path = str(f\"{train_folder}/{img_id}_{augmentation_name}.jpg\")\n",
        "        save_image(image, save_path)\n",
        "\n",
        "        original_index = bbox_indices[i]\n",
        "        new_entry = {\n",
        "            'Folder': original_df.loc[original_index, 'Folder'],\n",
        "            'Filename': f\"{img_id}_{augmentation_name}.jpg\",\n",
        "            'Path': save_path,\n",
        "            'Source': original_df.loc[original_index, 'Source'],\n",
        "            'Width': original_df.loc[original_index, 'Width'],\n",
        "            'Height': original_df.loc[original_index, 'Height'],\n",
        "            'Depth': original_df.loc[original_index, 'Depth'],\n",
        "            'Segmented': original_df.loc[original_index, 'Segmented'],\n",
        "            'Object Name': original_df.loc[original_index, 'Object Name'],\n",
        "            'Object Pose': original_df.loc[original_index, 'Object Pose'],\n",
        "            'Object Truncated': original_df.loc[original_index, 'Object Truncated'],\n",
        "            'Object Difficult': original_df.loc[original_index, 'Object Difficult'],\n",
        "            'Bounding Box': [x_min, y_min, x_max, y_max]\n",
        "        }\n",
        "\n",
        "        new_rows.append(new_entry)\n",
        "\n",
        "    new_df = pd.DataFrame(new_rows)\n",
        "    original_df = pd.concat([original_df, new_df], ignore_index=True)\n",
        "\n",
        "    return original_df\n",
        "\n",
        "\n",
        "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "# Function name:        organize_image_augmentation_and_saving\n",
        "# Function Parameter:   image > contains the image information\n",
        "#                       save_path > path under which the images are\n",
        "#                        stored at\n",
        "#                       img_id > unique image name, taken from the row\n",
        "#                        \"Filename\" in the data frame\n",
        "#                       bboxes > normalized bounding box data\n",
        "#                       augmentation_list > list that contains the\n",
        "#                        different augmentations that should be done\n",
        "#                        for every image\n",
        "#                       original_df > stores the latest data frame\n",
        "# Description:          Function to apply the augmentations\n",
        "#                        defined in the augmentation_list to the\n",
        "#                        images, save each augmented image, and\n",
        "#                        update the data frame (\"original_df\") with\n",
        "#                        the new annotation data.\n",
        "# Return:               original_df > stores the latest data frame\n",
        "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "def organize_image_augmentation_and_saving(image, img_id, bboxes, augmentation_list, original_df):\n",
        "    bbox_indices = original_df.loc[original_df.Filename == f\"{img_id}.jpg\"].index.tolist()\n",
        "    for aug_name, aug_func in augmentation_list:\n",
        "        transformed_img, transformed_bboxes = apply_augmentation(image, bboxes, aug_func)\n",
        "        original_df = organize_image_saving_and_annotation_data(transformed_img, img_id, aug_name, transformed_bboxes,\n",
        "                                                                original_df, bbox_indices)\n",
        "\n",
        "    return original_df\n",
        "\n",
        "\n",
        "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "# Function name:        apply_augmentation\n",
        "# Function Parameter:   image > contains the image information\n",
        "#                       save_path > path under which the images are\n",
        "#                        stored at\n",
        "#                       bboxes > normalized bounding box data\n",
        "#                       augmentation > stores the augmentation data\n",
        "#                       original_df > stores the latest data frame\n",
        "# Description:          Function to apply a given augmentation to an\n",
        "#                        image and its bounding boxes.\n",
        "# Return:               transformed_image > stores the augmented image\n",
        "#                       transformed_bboxes > stores the data for the\n",
        "#                        augmented bounding boxes for that image\n",
        "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "def apply_augmentation(image, bboxes, augmentation):\n",
        "    transformed = augmentation(image=image, bboxes=bboxes, labels=np.ones(len(bboxes)))\n",
        "    transformed_image = transformed['image']\n",
        "    transformed_bboxes = transformed['bboxes']\n",
        "    return transformed_image, transformed_bboxes\n",
        "\n",
        "\n",
        "# ===========================================================================================================\n",
        "# ================================================= \"MAIN\" ==================================================\n",
        "# ===========================================================================================================\n",
        "df = load_data()\n",
        "\n",
        "bbox_params = {'format': 'pascal_voc', 'label_fields': ['labels']}\n",
        "\n",
        "albumentation_list = [\n",
        "    ('RandomFog', A.Compose([A.RandomFog(p=1)], bbox_params=bbox_params)),\n",
        "    ('RandomBrightness', A.Compose([A.RandomBrightness(p=1)], bbox_params=bbox_params)),\n",
        "    ('RGBShift', A.Compose([A.RGBShift(p=1)], bbox_params=bbox_params)),\n",
        "    ('RandomSnow', A.Compose([A.RandomSnow(p=1)], bbox_params=bbox_params)),\n",
        "    ('RandomContrast', A.Compose([A.RandomContrast(limit=0.5, p=1)], bbox_params=bbox_params))\n",
        "]\n",
        "\n",
        "for img_id in df['Filename'].str[:-4].unique():\n",
        "    chosen_img = read_img(img_id)\n",
        "    bboxes = read_bboxes(f\"{img_id}.jpg\", df, chosen_img.shape)\n",
        "    df = organize_image_augmentation_and_saving(chosen_img, img_id, bboxes, albumentation_list, df)\n",
        "\n",
        "df.to_csv('/content/org_imgs_bb.csv', index=False)\n"
      ],
      "metadata": {
        "id": "dnSbQElDPrA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/csv_to_xml.py"
      ],
      "metadata": {
        "id": "7pd3_--M9pSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "!zip -r images.zip images"
      ],
      "metadata": {
        "id": "5gxomnJHtAeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ..\n",
        "%cd /home/\n",
        "!zip -r dataset_improvement.zip /content"
      ],
      "metadata": {
        "id": "Th92CnutsZ3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('/home/dataset_improvement.zip')"
      ],
      "metadata": {
        "id": "Mwnt03M4shuZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}